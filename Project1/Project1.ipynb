{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMP30027 Machine learning Project 1: Gaining Information about Naive Bayes\n",
    "# Author: Jordan Ung <jordanu@student.unimelb.edu.au> [729938]\n",
    "# Last Modified: 28.03.19\n",
    "\n",
    "#### GENERAL GUIDE\n",
    "# Read In And Inspect The Data\n",
    "# Check for missing value - (1) delete rows with missing values, (2) Impute the missing values with dataset\n",
    "# Check for anomalously extreme values\n",
    "\n",
    "# QUESTIONS TO ASK:\n",
    "# Should I handle datasets with Missing values and ones without differently?\n",
    "# In tht case do I need to hardcode it or iterate through the whole dataset once\n",
    "# to find presence of missing values?\n",
    "\n",
    "\n",
    "#### TODO\n",
    "# Calculate conditional probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess takes the name of a file and returns a list of instances\n",
    "# within that file, with each instance containing a list of attributes\n",
    "def preprocess(file_name):\n",
    "    dataset = []\n",
    "    with open(file_name, 'r') as file:\n",
    "        # Add each instance to a list to be used later\n",
    "        for line in file.readlines():\n",
    "            dataset.append(line.strip().split(','))\n",
    "            \n",
    "    # Group all the instances with the same class together\n",
    "    dataset = sorted(dataset, key=lambda x: x[-1])\n",
    "    return dataset\n",
    "\n",
    "data_file = 'anneal.csv'\n",
    "missing_value_files = ['breast-cancer.csv', 'hepatitis.csv', 'hypothyroid.csv', 'mushroom.csv', 'primary-tumor.csv']\n",
    "# preprocess(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train takes a list of instances and returns a 2-tuple, containing\n",
    "# a list of counts representing the class distribution and a list\n",
    "# of lists of dictionaries representing the conditional probabilities\n",
    "def train(instance_list, missing_value):\n",
    "    data_info = ([], [])\n",
    "    classes = {}\n",
    "    \n",
    "    for instance in instance_list:\n",
    "        # Check for missing values and delete rows containing them\n",
    "        if missing_value in instance:\n",
    "            instance_list.remove(instance)\n",
    "            \n",
    "        class_type = instance[-1]\n",
    "        # Calculate the frequencies of all the class values\n",
    "        if class_type not in classes:\n",
    "            classes[class_type] = 1\n",
    "        else:\n",
    "            classes[class_type] += 1\n",
    "            \n",
    "    # Create a data structure to store all the attribute probabilities w.r.t each class\n",
    "    for i in range(len(classes)):\n",
    "        data_info[1].append([])\n",
    "        for j in range(len(instance_list[0]) - 1):\n",
    "            data_info[1][i].append({})\n",
    "\n",
    "    # Tally amount of class values compared to total number of instances\n",
    "    num_of_instances = len(instance_list)\n",
    "    for type in classes:\n",
    "        data_info[0].append(classes[type])\n",
    "        \n",
    "    current_class = instance_list[0][-1]\n",
    "    class_index = 0\n",
    "    \n",
    "    # Tally each value in each attribute for each class\n",
    "    for data in instance_list:\n",
    "        attribute_num = 0\n",
    "        \n",
    "        # Check that the instances' class is the same as the previous instance\n",
    "        if data[-1] != current_class:\n",
    "            current_class = data[-1]\n",
    "            class_index += 1\n",
    "        \n",
    "        # Input each instance's attribute into the appropriate dictionary\n",
    "        for attribute in data[:-1]:\n",
    "            if attribute in data_info[1][class_index][attribute_num]:\n",
    "                data_info[1][class_index][attribute_num][attribute] += 1\n",
    "            else:\n",
    "                data_info[1][class_index][attribute_num][attribute] = 1\n",
    "            attribute_num += 1\n",
    "            \n",
    "    # Find conditional probability of each attribute value given a certain class\n",
    "    for i in range(len(data_info[0])):\n",
    "        for j in data_info[1][i]:\n",
    "            # Convert attribute value tally to probability\n",
    "            for k in j:\n",
    "                j[k] = j[k] / data_info[0][i]\n",
    "        data_info[0][i] = data_info[0][i] / num_of_instances\n",
    "\n",
    "    return data_info # Return the 2-tuple\n",
    "# train(preprocess(missing_value_files[0]), \"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should predict the class for an instance or a set of instances, based on a trained model \n",
    "def predict(model, instance):\n",
    "    \n",
    "    return # Return a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should evaluate a set of predictions, in a supervised context \n",
    "def evaluate():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should calculate the Information Gain of an attribute or a set of attribute, with respect to the class\n",
    "def info_gain():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [], [], [], [], [], [], [], [], []]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'dict' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e8dc01ab512f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"car\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bird\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"food\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'dict' and 'int'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
