{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMP30027 Machine learning Project 1: Gaining Information about Naive Bayes\n",
    "# Author: Jordan Ung <jordanu@student.unimelb.edu.au> [729938]\n",
    "# Last Modified: 24.03.19\n",
    "\n",
    "#### GENERAL GUIDE\n",
    "# Read In And Inspect The Data\n",
    "# Check for missing value - (1) delete rows with missing values, (2) Impute the missing values with dataset\n",
    "# Check for anomalously extreme values\n",
    "\n",
    "# QUESTIONS TO ASK:\n",
    "# Should I handle datasets with Missing values and ones without differently?\n",
    "# In tht case do I need to hardcode it or iterate through the whole dataset once\n",
    "# to find presence of missing values?\n",
    "\n",
    "# Is hardcoding bad: ->See \"?\", is it okay if I add another\n",
    "# Parameter to the function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess takes the name of a file and returns a list of instances\n",
    "# within that file, with each instance containing a list of attributes\n",
    "def preprocess(file_name):\n",
    "    dataset = []\n",
    "    with open(file_name, 'r') as file:\n",
    "        # Add each instance to a list to be used later\n",
    "        for line in file.readlines():\n",
    "            dataset.append(line.strip().split(','))\n",
    "    return dataset\n",
    "\n",
    "data_file = 'anneal.csv'\n",
    "missing_value_files = ['breast-cancer.csv', 'hepatitis.csv', 'hypothyroid.csv', 'mushroom.csv', 'primary-tumor.csv']\n",
    "# preprocess(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.30324909747292417, 0.6967509025270758],\n",
       " [[[], [], [], [], [], [], [], [], [], []],\n",
       "  [[], [], [], [], [], [], [], [], [], []]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train takes a list of instances and returns a 2-tuple, containing\n",
    "# a list of counts representing the class distribution and a list\n",
    "# of lists of dictionaries representing the conditional probabilities\n",
    "def train(instance_list):\n",
    "    data_info = ([], [])\n",
    "    classes = {}\n",
    "    # TODO\n",
    "    # Need to create a list of lists of dictionaries for repping the\n",
    "    # conditional probabilities of each attribute w.r.t to the classes\n",
    "    \n",
    "    for instance in instance_list:\n",
    "        # Check for missing values and delete rows containing them\n",
    "        if \"?\" in instance:\n",
    "            instance_list.remove(instance)\n",
    "        class_type = instance[-1]\n",
    "        \n",
    "        # Calculate the frequencies of all the class values\n",
    "        if class_type not in classes:\n",
    "            classes[class_type] = 1\n",
    "        else:\n",
    "            classes[class_type] += 1\n",
    "    \n",
    "    # Create a data structure to store all the attribute probabilities w.r.t each class\n",
    "    num_of_attributes = len(instance_list[0])\n",
    "    attribute_data = [[]] * num_of_attributes\n",
    "    for i in range(len(classes)):\n",
    "        data_info[1].append(attribute_data)\n",
    "\n",
    "    # Calculate probability of each class value compared to total number of instances\n",
    "    num_of_instances = len(instance_list)\n",
    "    for type in classes:\n",
    "        data_info[0].append(classes[type] * 1.0 / num_of_instances)\n",
    "        \n",
    "    # Calculate probability of each value in each attribute for each class\n",
    "    for i in range(len(num_of_attributes)):\n",
    "        values = {}\n",
    "        for j in range(len(num_of_instances))\n",
    "        \n",
    "        \n",
    "    return data_info # Return the 2-tuple\n",
    "train(preprocess(missing_value_files[0]))\n",
    "# train(preprocess(data_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should predict the class for an instance or a set of instances, based on a trained model \n",
    "def predict(model, instance):\n",
    "    return # Return a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should evaluate a set of predictions, in a supervised context \n",
    "def evaluate():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should calculate the Information Gain of an attribute or a set of attribute, with respect to the class\n",
    "def info_gain():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [], [], [], [], [], [], [], [], []]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
