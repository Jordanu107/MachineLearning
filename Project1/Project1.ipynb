{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMP30027 Machine learning Project 1: Gaining Information about Naive Bayes\n",
    "# Author: Jordan Ung <jordanu@student.unimelb.edu.au> [729938]\n",
    "# Last Modified: 31.03.19\n",
    "\n",
    "#### GENERAL GUIDE\n",
    "# Read In And Inspect The Data\n",
    "# Check for missing value - (1) delete rows with missing values, (2) Impute the missing values with dataset\n",
    "# Check for anomalously extreme values\n",
    "\n",
    "# QUESTIONS TO ASK:\n",
    "# Should I handle datasets with Missing values and ones without differently?\n",
    "# In tht case do I need to hardcode it or iterate through the whole dataset once\n",
    "# to find presence of missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess takes the name of a file and returns a list of instances\n",
    "# within that file, with each instance containing a list of attributes\n",
    "def preprocess(file_name):\n",
    "    dataset = []\n",
    "    with open(file_name, 'r') as file:\n",
    "        # Add each instance to a list to be used later\n",
    "        for line in file.readlines():\n",
    "            dataset.append(line.strip().split(','))\n",
    "            \n",
    "    # Group all the instances with the same class together\n",
    "    dataset = sorted(dataset, key=lambda x: x[-1])\n",
    "    return dataset\n",
    "\n",
    "data_file = 'anneal.csv'\n",
    "missing_value_files = ['breast-cancer.csv', 'hepatitis.csv', 'hypothyroid.csv', 'mushroom.csv', 'primary-tumor.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train takes a list of instances and returns a 3-tuple, containing\n",
    "# the classes, a list of counts of each class in the dataset and a\n",
    "# list of each class with a list inside each of every attribute,\n",
    "# containing a dictionary of the count of each unique attribute value\n",
    "def train(instance_list, missing_value):\n",
    "    data_info = ([], [], [])\n",
    "#     classes = {}\n",
    "    \n",
    "#     for instance in instance_list:\n",
    "#         # Check for missing values and delete rows containing them\n",
    "#         if missing_value in instance:\n",
    "#             instance_list.remove(instance)\n",
    "            \n",
    "#         class_type = instance[-1]\n",
    "#         # Calculate the frequencies of all the class values\n",
    "#         if class_type not in classes:\n",
    "#             classes[class_type] = 1\n",
    "#             data_info[0].append(class_type)\n",
    "#         else:\n",
    "#             classes[class_type] += 1\n",
    "#     print(classes)\n",
    "            \n",
    "#     # Create a data structure to store all the attribute probabilities w.r.t each class\n",
    "#     for i in range(len(classes)):\n",
    "#         data_info[2].append([])\n",
    "#         for j in range(len(instance_list[0]) - 1):\n",
    "#             data_info[2][i].append({})\n",
    "\n",
    "#     # Amount of instances that are of a certain class\n",
    "#     for class_value in classes:\n",
    "#         data_info[1].append(classes[class_value])\n",
    "        \n",
    "        \n",
    "#     print(data_info)\n",
    "#     for i in data_info[2]:\n",
    "#         print(len(i))\n",
    "    \n",
    "    current_class = instance_list[0][-1]\n",
    "    data_info[2].append({})\n",
    "    class_index = 0\n",
    "    number_of_instances = 0\n",
    "    # Tally each value in each attribute for each class\n",
    "    for data in instance_list:\n",
    "        attribute_num = 0\n",
    "\n",
    "        # New class has been detected\n",
    "        if data[-1] != current_class:\n",
    "            # Add data structure to support new class\n",
    "            data_info[2].append({})\n",
    "            class_index += 1\n",
    "            current_class = data[-1]\n",
    "            \n",
    "            # Input information from previous class to data structure\n",
    "            data_info[0].append(current_class)\n",
    "            data_info[1].append(number_of_instances)\n",
    "            number_of_instances = 0\n",
    "            \n",
    "            # Add attribute for each \n",
    "        \n",
    "        # Input each instance's attribute into the appropriate dictionary\n",
    "        for attribute in data[:-1]:\n",
    "#             print(\"Class Index:\", class_index, \"|\", data_info[0][class_index])\n",
    "#             print(\"Attribtue Value\", attribute)\n",
    "#             print(\"Attribute Number:\", attribute_num)\n",
    "#             print(\"--------------------\")\n",
    "            if attribute in data_info[2][class_index][attribute_num]:\n",
    "                data_info[2][class_index][attribute_num][attribute] += 1\n",
    "            else:\n",
    "                data_info[2][class_index][attribute_num][attribute] = 1\n",
    "            attribute_num += 1\n",
    "        \n",
    "        number_of_instances += 1\n",
    "        \n",
    "\n",
    "    return data_info # Return the 3-tuple\n",
    "# train(preprocess(missing_value_files[0]), \"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should predict the class for an instance or a set of instances, based on a trained model \n",
    "def predict(model, instances):\n",
    "    predicted_classes = []\n",
    "    \n",
    "    # Find class prediction for each class\n",
    "    for data in instances:\n",
    "        attribute_number = 0\n",
    "        probability_of_class = []\n",
    "        \n",
    "        # Find probability of an instance being of a particular class\n",
    "        for class_index in range(len(model[2])):\n",
    "            sum = 1.0\n",
    "            for attribute in model[2][class_index]:\n",
    "                if data[attribute_number] in attribute:\n",
    "                    sum *= attribute[data[attribute_number]] / model[1][class_index]\n",
    "                else:\n",
    "                    sum /= len(model[2][class_index])\n",
    "            probability_of_class.append(sum)\n",
    "        \n",
    "        class_index = 0\n",
    "        highest_probability = 0\n",
    "        # Find the class with the highest probability\n",
    "        for i in range(len(probability_of_class)):\n",
    "            if probability_of_class[i] > highest_probability:\n",
    "                highest_probability = probability_of_class[i]\n",
    "                class_index = i\n",
    "#                 print(\"Higher\")\n",
    "#             elif probability_of_class[i] < highest_probability:\n",
    "#                 print(\"Less Than\")\n",
    "#             else:\n",
    "#                 print(\"Equal Too\")\n",
    "        predicted_classes.append(model[0][class_index])\n",
    "    return predicted_classes # Return a list of predicted classes\n",
    "\n",
    "# predict(train(preprocess(missing_value_files[1]), \"?\"), preprocess(missing_value_files[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-a3a47bab05a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# preprocess(missing_value_files[-1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_value_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# for i in missing_value_files:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-167-2f2ce7ebcd75>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(instance_list, missing_value)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m#             print(\"Attribute Number:\", attribute_num)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m#             print(\"--------------------\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattribute_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0mdata_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattribute_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# Evaluates certain metrics of performance of the predictor model\n",
    "def evaluate(predictions, dataset):\n",
    "    tries = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == dataset[i][-1]:\n",
    "            correct += 1\n",
    "#         else:\n",
    "#             print(\"My attempt:\", predictions[i], \"whereas the correct class was\", dataset[i][-1])\n",
    "        tries += 1\n",
    "    print(\"-----------------------------------\")\n",
    "    print(\"Correct:\", correct, \"out of\", tries, \"attempts.\")\n",
    "    print(\"Accuracy Rate (%): \", correct / tries * 100)\n",
    "    print(\"-----------------------------------\")\n",
    "    return\n",
    "# preprocess(missing_value_files[-1])\n",
    "train(preprocess(missing_value_files[-1]), \"?\")\n",
    "\n",
    "# for i in missing_value_files:\n",
    "#     evaluate(predict(train(preprocess(i), \"?\"), preprocess(i)), preprocess(i))\n",
    "# evaluate(predict(train(preprocess(missing_value_files[-1]), \"?\"), preprocess(missing_value_files[-1])), preprocess(missing_value_files[-1]))\n",
    "\n",
    "# evaluate(predict(train(preprocess(data_file), \"?\"), preprocess(data_file)), preprocess(data_file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should calculate the Information Gain of an attribute or a set of attribute, with respect to the class\n",
    "def info_gain():\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'value'}, {'key': 'value'}, {'key': 'value'}, {'key': 'value'}, {'key': 'value'}]\n",
      "[{}, {'key': 'value'}, {}, {}, {}]\n"
     ]
    }
   ],
   "source": [
    "a = [{}] * 5\n",
    "\n",
    "b = []\n",
    "for i in range(5):\n",
    "    b.append({})\n",
    "    \n",
    "\n",
    "b[1]['key'] = 'value'\n",
    "a[1]['key'] = 'value'\n",
    "print(a)\n",
    "print(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
