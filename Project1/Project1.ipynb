{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMP30027 Machine learning Project 1: Gaining Information about Naive Bayes\n",
    "# Author: Jordan Ung <jordanu@student.unimelb.edu.au> [729938]\n",
    "# Last Modified: 04.04.19\n",
    "\n",
    "#### GENERAL GUIDE\n",
    "# Read In And Inspect The Data\n",
    "# Check for missing value - (1) delete rows with missing values, (2) Impute the missing values with dataset\n",
    "# Check for anomalously extreme values\n",
    "\n",
    "# TODO\n",
    "\n",
    "# Work on Question 1, and Question 4\n",
    "# Implement a Cross Evaluation Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess takes the name of a file and returns a list of instances\n",
    "# within that file, with each instance containing a list of attributes\n",
    "def preprocess(file_name):\n",
    "    dataset = []\n",
    "    with open(file_name, 'r') as file:\n",
    "        # Add each instance to a list to be used later\n",
    "        for line in file.readlines():\n",
    "            dataset.append(line.strip().split(','))\n",
    "            \n",
    "    # Group all the instances with the same class together\n",
    "    dataset = sorted(dataset, key=lambda x: x[-1])\n",
    "    return dataset\n",
    "\n",
    "all_files = ['anneal.csv', 'breast-cancer.csv', 'car.csv', 'cmc.csv', 'hepatitis.csv', 'hypothyroid.csv', 'mushroom.csv', 'nursery.csv', 'primary-tumor.csv']\n",
    "new_file = \"_unit_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train takes a list of instances and returns a 3-tuple containing:\n",
    "# A dictionary of the class distribution of all classes in the dataset\n",
    "# A list of dictionaries, tallying each attribute value for every attribute\n",
    "# A dictionary (for each class) of lists of dictionaries tallying \n",
    "# attribute values for every attribute of a particular class\n",
    "def train(instance_list, missing_value):\n",
    "    data_info = ({}, [], {})\n",
    "\n",
    "    current_class = instance_list[0][-1]\n",
    "    data_info[0][current_class] = 0\n",
    "    data_info[2][current_class] = []\n",
    "    class_index = 0\n",
    "    \n",
    "    # Add attribute lists to store the unique attribute values in\n",
    "    for i in range(len(instance_list[0]) - 1):\n",
    "        data_info[1].append({})\n",
    "        data_info[2][current_class].append({})\n",
    "    \n",
    "    # Tally each value in each attribute for each class\n",
    "    for data in instance_list:\n",
    "#         print(data)\n",
    "        attribute_num = 0\n",
    "\n",
    "        # New class has been detected\n",
    "        if data[-1] != current_class:\n",
    "\n",
    "            # Add data structure to support new class\n",
    "            current_class = data[-1]\n",
    "            data_info[0][current_class] = 0\n",
    "            data_info[2][current_class] = []\n",
    "            class_index += 1\n",
    "            \n",
    "            # Add dictionary for each attribute\n",
    "            for i in range(len(data) - 1):\n",
    "                data_info[2][current_class].append({})\n",
    "        \n",
    "        # Input each instance's attribute into the appropriate dictionary\n",
    "        for attribute in data[:-1]:\n",
    "            \n",
    "            if attribute in data_info[1][attribute_num]:\n",
    "                data_info[1][attribute_num][attribute] += 1\n",
    "            else:\n",
    "                data_info[1][attribute_num][attribute] = 1\n",
    "                \n",
    "            if attribute in data_info[2][current_class][attribute_num]:\n",
    "                data_info[2][current_class][attribute_num][attribute] += 1\n",
    "            else:\n",
    "                data_info[2][current_class][attribute_num][attribute] = 1\n",
    "            attribute_num += 1\n",
    "        \n",
    "        data_info[0][current_class] += 1\n",
    "        \n",
    "    return data_info # Return the 3-tuple\n",
    "\n",
    "\n",
    "# train(preprocess(missing_value_files[0]), \"?\")\n",
    "# train(preprocess(new_file), \"?\")\n",
    "\n",
    "# train(preprocess(missing_value_files[-1]), \"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict function takes two arguments, a learner model and a\n",
    "# dataset and attempts to predict the class of a certain instance\n",
    "def predict(model, instances):\n",
    "    predicted_classes = []\n",
    "    possible_classes = list(model[0].keys())\n",
    "    \n",
    "    # Find class prediction for each instance\n",
    "    for data in instances:\n",
    "        probability_of_class = 1.0\n",
    "        class_probabilities = []\n",
    "        \n",
    "        # Calculate probability of the instance belonging to a particular class\n",
    "        for class_name in possible_classes:\n",
    "            attribute_list = model[2][class_name]\n",
    "            \n",
    "            # Multiply all of the attribute probabilities\n",
    "            for attribute in range(len(attribute_list)):\n",
    "                if data[attribute] in attribute_list[attribute]:\n",
    "                    probability_of_class *= (attribute_list[attribute][data[attribute]] + 1) / (len(model[1][attribute].keys()) + model[0][class_name])\n",
    "                else:\n",
    "                    probability_of_class /= (len(model[1][attribute].keys()) + model[0][class_name])\n",
    "            probability_of_class *= model[0][class_name] / sum(model[0].values())\n",
    "            class_probabilities.append(probability_of_class)\n",
    "            probability_of_class = 1.0\n",
    "        \n",
    "        class_index = 0\n",
    "        highest_probability = 0\n",
    "        # Predict the class with the highest probability\n",
    "        for i in range(len(class_probabilities)):\n",
    "            if class_probabilities[i] > highest_probability:\n",
    "                highest_probability = class_probabilities[i]\n",
    "                class_index = i\n",
    "        predicted_classes.append(possible_classes[class_index])\n",
    "        \n",
    "    return predicted_classes # Return a list of predicted classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anneal.csv\n",
      "Correct: 828 out of 898\n",
      "Accuracy Rate (%):  92.2\n",
      "-----------------------------------\n",
      "breast-cancer.csv\n",
      "Correct: 216 out of 286\n",
      "Accuracy Rate (%):  75.52\n",
      "-----------------------------------\n",
      "car.csv\n",
      "Correct: 1506 out of 1728\n",
      "Accuracy Rate (%):  87.15\n",
      "-----------------------------------\n",
      "cmc.csv\n",
      "Correct: 745 out of 1473\n",
      "Accuracy Rate (%):  50.58\n",
      "-----------------------------------\n",
      "hepatitis.csv\n",
      "Correct: 130 out of 155\n",
      "Accuracy Rate (%):  83.87\n",
      "-----------------------------------\n",
      "hypothyroid.csv\n",
      "Correct: 3011 out of 3163\n",
      "Accuracy Rate (%):  95.19\n",
      "-----------------------------------\n",
      "mushroom.csv\n",
      "Correct: 7772 out of 8124\n",
      "Accuracy Rate (%):  95.67\n",
      "-----------------------------------\n",
      "nursery.csv\n",
      "Correct: 11703 out of 12960\n",
      "Accuracy Rate (%):  90.3\n",
      "-----------------------------------\n",
      "primary-tumor.csv\n",
      "Correct: 192 out of 339\n",
      "Accuracy Rate (%):  56.64\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Evaluates the performance of the predictor model\n",
    "# The metric/s evaluated are as follows: Accuracy\n",
    "def evaluate(predictions, dataset):\n",
    "    tries = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == dataset[i][-1]:\n",
    "            correct += 1\n",
    "        tries += 1\n",
    "        \n",
    "    print(\"Correct:\", correct, \"out of\", tries)\n",
    "    print(\"Accuracy Rate (%): \", round(correct / tries * 100, 2))\n",
    "    print(\"-----------------------------------\")\n",
    "    return\n",
    "\n",
    "\n",
    "for i in all_files:\n",
    "    print(i)\n",
    "    evaluate(predict(train(preprocess(i), \"?\"), preprocess(i)), preprocess(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'cold': 2, 'flu': 3}, [{'no': 1, 'mild': 2, 'severe': 2}, {'severe': 2, 'no': 1, 'mild': 2}, {'normal': 4, 'high': 1}, {'yes': 4, 'no': 1}], {'cold': [{'no': 1, 'mild': 1}, {'severe': 1, 'no': 1}, {'normal': 2}, {'yes': 1, 'no': 1}], 'flu': [{'severe': 2, 'mild': 1}, {'mild': 2, 'severe': 1}, {'high': 1, 'normal': 2}, {'yes': 3}]})\n",
      "0.9709505944546686\n",
      "Attribute: no\n",
      "Attribute: mild\n",
      "Attribute: severe\n",
      "{'no': 1, 'mild': 2, 'severe': 2}\n",
      "Attribute: severe\n",
      "Attribute: no\n",
      "Attribute: mild\n",
      "{'severe': 2, 'no': 1, 'mild': 2}\n",
      "Attribute: normal\n",
      "Attribute: high\n",
      "{'normal': 4, 'high': 1}\n",
      "Attribute: yes\n",
      "Attribute: no\n",
      "{'yes': 4, 'no': 1}\n",
      "[0.5709505944546686, 0.5709505944546686, 0.17095059445466854, 0.3219280948873623]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5709505944546686,\n",
       " 0.5709505944546686,\n",
       " 0.17095059445466854,\n",
       " 0.3219280948873623]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Information Gain of an attribute given the root node\n",
    "# In other words, which attribute is best to split the instances\n",
    "def info_gain(model):\n",
    "    info_gain_values = []\n",
    "    print(model)\n",
    "    \n",
    "    # Calculate Entropy of Root Node, a.k.a class distribution entropy\n",
    "    root_entropy = 0\n",
    "    for class_name in model[0]:\n",
    "        pr_attribute = model[0][class_name] * 1.0 / sum(model[0].values())\n",
    "        root_entropy -= pr_attribute * math.log2(pr_attribute)\n",
    "    \n",
    "    # Traverse each attribute in model\n",
    "    for attribute_index in range(len(model[1])):\n",
    "        mean_info_list = []\n",
    "        mean_info = 0\n",
    "        \n",
    "        # Calculate entropy of each unique attribute value\n",
    "        for attribute in model[1][attribute_index]:\n",
    "            print(\"Attribute:\", attribute)\n",
    "            entropy = 0\n",
    "            attribute_freq = []\n",
    "            # Append each class' attribute's frequency\n",
    "            for class_index in model[0].keys():\n",
    "                if attribute in model[2][class_index][attribute_index]:\n",
    "                    attribute_freq.append(model[2][class_index][attribute_index][attribute])\n",
    "            \n",
    "            # Calculate entropy and add to mean_info\n",
    "            if len(attribute_freq) == 1:\n",
    "                continue\n",
    "            else:\n",
    "                for element in attribute_freq:\n",
    "                    probability = element * 1.0 / sum(attribute_freq)\n",
    "                    entropy -= probability * math.log2(probability)\n",
    "            \n",
    "            # Calculate Mean Info of an attribute\n",
    "            mean_info = entropy * (model[1][attribute_index][attribute] / sum(model[1][attribute_index].values()))\n",
    "            mean_info_list.append(mean_info)\n",
    "            \n",
    "        # Calculate the IG for an attribute with respect to the root node\n",
    "        for value in mean_info_list:\n",
    "            info_gain_values.append(root_entropy - value)\n",
    "    return info_gain_values\n",
    "\n",
    "info_gain(train(preprocess(new_file), \"?\"))\n",
    "# for i in all_files:\n",
    "#     print(i)\n",
    "#     info_gain(train(preprocess(i), \"?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nQuestion 1: The Naive Bayes classifiers can be seen to vary, in terms of their effectiveness on \\nthe given datasets (e.g. in terms of Accuracy). Consider the Information Gain of each attribute, \\nrelative to the class distribution - does this help to explain the classifiers' behaviour? \\nIdentify any results that are particularly surprising, and explain why they occur.\\n\\n\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Question 1: The Naive Bayes classifiers can be seen to vary, in terms of their effectiveness on \n",
    "the given datasets (e.g. in terms of Accuracy). Consider the Information Gain of each attribute, \n",
    "relative to the class distribution - does this help to explain the classifiers' behaviour? \n",
    "Identify any results that are particularly surprising, and explain why they occur.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546687"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2/5*math.log2(5/2) + 3/5*math.log2(5/3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
