{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMP30027 Machine learning Project 1: Gaining Information about Naive Bayes\n",
    "# Author: Jordan Ung <jordanu@student.unimelb.edu.au> [729938]\n",
    "# Last Modified: 03.04.19\n",
    "\n",
    "#### GENERAL GUIDE\n",
    "# Read In And Inspect The Data\n",
    "# Check for missing value - (1) delete rows with missing values, (2) Impute the missing values with dataset\n",
    "# Check for anomalously extreme values\n",
    "\n",
    "# TODO\n",
    "\n",
    "# Work on Question 1, and Question 4\n",
    "# Implement a Cross Evaluation Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess takes the name of a file and returns a list of instances\n",
    "# within that file, with each instance containing a list of attributes\n",
    "def preprocess(file_name):\n",
    "    dataset = []\n",
    "    with open(file_name, 'r') as file:\n",
    "        # Add each instance to a list to be used later\n",
    "        for line in file.readlines():\n",
    "            dataset.append(line.strip().split(','))\n",
    "            \n",
    "    # Group all the instances with the same class together\n",
    "    dataset = sorted(dataset, key=lambda x: x[-1])\n",
    "    return dataset\n",
    "\n",
    "data_file = 'anneal.csv'\n",
    "new_file = \"_unit_test.csv\"\n",
    "missing_value_files = ['breast-cancer.csv', 'hepatitis.csv', 'hypothyroid.csv', 'mushroom.csv', 'primary-tumor.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train takes a list of instances and returns a 3-tuple containing:\n",
    "# A dictionary of the class distribution of all classes in the dataset\n",
    "# A list of dictionaries, tallying each attribute value for every attribute\n",
    "# A dictionary (for each class) of lists of dictionaries tallying \n",
    "# attribute values for every attribute of a particular class\n",
    "def train(instance_list, missing_value):\n",
    "    data_info = ({}, [], {})\n",
    "\n",
    "    current_class = instance_list[0][-1]\n",
    "    data_info[0][current_class] = 0\n",
    "    data_info[2][current_class] = []\n",
    "    class_index = 0\n",
    "    \n",
    "    # Add attribute lists to store the unique attribute values in\n",
    "    for i in range(len(instance_list[0]) - 1):\n",
    "        data_info[1].append({})\n",
    "        data_info[2][current_class].append({})\n",
    "    \n",
    "    # Tally each value in each attribute for each class\n",
    "    for data in instance_list:\n",
    "#         print(data)\n",
    "        attribute_num = 0\n",
    "\n",
    "        # New class has been detected\n",
    "        if data[-1] != current_class:\n",
    "\n",
    "            # Add data structure to support new class\n",
    "            current_class = data[-1]\n",
    "            data_info[0][current_class] = 0\n",
    "            data_info[2][current_class] = []\n",
    "            class_index += 1\n",
    "            \n",
    "            # Add dictionary for each attribute\n",
    "            for i in range(len(data) - 1):\n",
    "                data_info[2][current_class].append({})\n",
    "        \n",
    "        # Input each instance's attribute into the appropriate dictionary\n",
    "        for attribute in data[:-1]:\n",
    "            \n",
    "            if attribute in data_info[1][attribute_num]:\n",
    "                data_info[1][attribute_num][attribute] += 1\n",
    "            else:\n",
    "                data_info[1][attribute_num][attribute] = 1\n",
    "                \n",
    "            if attribute in data_info[2][current_class][attribute_num]:\n",
    "                data_info[2][current_class][attribute_num][attribute] += 1\n",
    "            else:\n",
    "                data_info[2][current_class][attribute_num][attribute] = 1\n",
    "            attribute_num += 1\n",
    "        \n",
    "        data_info[0][current_class] += 1\n",
    "        \n",
    "    return data_info # Return the 3-tuple\n",
    "\n",
    "\n",
    "# train(preprocess(missing_value_files[0]), \"?\")\n",
    "# train(preprocess(new_file), \"?\")\n",
    "\n",
    "# train(preprocess(missing_value_files[-1]), \"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict function takes two arguments, a learner model and a\n",
    "# dataset and attempts to predict the class of a certain instance\n",
    "def predict(model, instances):\n",
    "    predicted_classes = []\n",
    "    possible_classes = list(model[0].keys())\n",
    "    \n",
    "    # Find class prediction for each instance\n",
    "    for data in instances:\n",
    "        probability_of_class = 1.0\n",
    "        class_probabilities = []\n",
    "        \n",
    "        # Calculate probability of the instance belonging to a particular class\n",
    "        for class_name in possible_classes:\n",
    "            attribute_list = model[2][class_name]\n",
    "            \n",
    "            # Multiply all of the attribute probabilities\n",
    "            for attribute in range(len(attribute_list)):\n",
    "                if data[attribute] in attribute_list[attribute]:\n",
    "                    probability_of_class *= (attribute_list[attribute][data[attribute]] + 1) / (len(model[1][attribute].keys()) + model[0][class_name])\n",
    "                else:\n",
    "                    probability_of_class /= (len(model[1][attribute].keys()) + model[0][class_name])\n",
    "            probability_of_class *= model[0][class_name] / sum(model[0].values())\n",
    "            class_probabilities.append(probability_of_class)\n",
    "            probability_of_class = 1.0\n",
    "        \n",
    "        class_index = 0\n",
    "        highest_probability = 0\n",
    "        # Predict the class with the highest probability\n",
    "        for i in range(len(class_probabilities)):\n",
    "            if class_probabilities[i] > highest_probability:\n",
    "                highest_probability = class_probabilities[i]\n",
    "                class_index = i\n",
    "        predicted_classes.append(possible_classes[class_index])\n",
    "        \n",
    "    return predicted_classes # Return a list of predicted classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluates the performance of the predictor model\n",
    "# The metric/s evaluated are as follows: Accuracy\n",
    "def evaluate(predictions, dataset):\n",
    "    tries = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == dataset[i][-1]:\n",
    "            correct += 1\n",
    "        tries += 1\n",
    "        \n",
    "    print(\"Correct:\", correct, \"out of\", tries)\n",
    "    print(\"Accuracy Rate (%): \", correct / tries * 100)\n",
    "    print(\"-----------------------------------\")\n",
    "    return\n",
    "\n",
    "\n",
    "# for i in missing_value_files:\n",
    "#     print(i)\n",
    "#     evaluate(predict(train(preprocess(i), \"?\"), preprocess(i)), preprocess(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Information Gain of an attribute given the root node\n",
    "# In other words, which attribute is best to split the instances\n",
    "def info_gain(model):\n",
    "    info_gain_values = []\n",
    "    \n",
    "    # Calculate Entropy of Root Node, a.k.a class distribution entropy\n",
    "    root_entropy = 0\n",
    "    for class_name in model[0]:\n",
    "        pr_attribute = model[0][class_name] * 1.0 / sum(model[0].values())\n",
    "        root_entropy -= pr_attribute * math.log2(pr_attribute)\n",
    "    \n",
    "    # Traverse each attribute in model\n",
    "    for attribute_index in range(len(model[1])):\n",
    "        mean_info_list = []\n",
    "        mean_info = 0\n",
    "        \n",
    "        # Calculate entropy of each unique attribute value\n",
    "        for attribute in model[1][attribute_index]:\n",
    "            entropy = 0\n",
    "            attribute_freq = []\n",
    "            # Append each class' attribute's frequency\n",
    "            for class_index in model[0].keys():\n",
    "                if attribute in model[2][class_index][attribute_index]:\n",
    "                    attribute_freq.append(model[2][class_index][attribute_index][attribute])\n",
    "            \n",
    "            # Calculate entropy and add to mean_info\n",
    "            if len(attribute_freq) == 1:\n",
    "                continue\n",
    "            else:\n",
    "                for element in attribute_freq:\n",
    "                    probability = element * 1.0 / sum(attribute_freq)\n",
    "                    entropy -= probability * math.log2(probability)\n",
    "            \n",
    "            # Calculate Mean Info of an attribute\n",
    "            mean_info = entropy * (model[1][attribute_index][attribute] / sum(model[1][attribute_index].values()))\n",
    "            mean_info_list.append(mean_info)\n",
    "            \n",
    "            # Calculate the IG for an attribute with respect to the root node\n",
    "            for value in mean_info_list:\n",
    "                info_gain_values.append(root_entropy - value)\n",
    "    \n",
    "    return info_gain_values\n",
    "\n",
    "# info_gain(train(preprocess(new_file), \"?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
