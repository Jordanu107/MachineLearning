{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMP30027 Machine learning Project 1: Gaining Information about Naive Bayes\n",
    "# Author: Jordan Ung <jordanu@student.unimelb.edu.au> [729938]\n",
    "# Last Modified: 01.04.19\n",
    "\n",
    "#### GENERAL GUIDE\n",
    "# Read In And Inspect The Data\n",
    "# Check for missing value - (1) delete rows with missing values, (2) Impute the missing values with dataset\n",
    "# Check for anomalously extreme values\n",
    "\n",
    "#TODO\n",
    "# Predict is NOT working, Train() seems to be fine. Find out the problem\n",
    "\n",
    "# Work on Info_Gain Function, why the fk is IG < 0\n",
    "# NOTE: Entropy > 0 is fine, for x possible attribute values, the entropy is at max log2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess takes the name of a file and returns a list of instances\n",
    "# within that file, with each instance containing a list of attributes\n",
    "def preprocess(file_name):\n",
    "    dataset = []\n",
    "    with open(file_name, 'r') as file:\n",
    "        # Add each instance to a list to be used later\n",
    "        for line in file.readlines():\n",
    "            dataset.append(line.strip().split(','))\n",
    "            \n",
    "    # Group all the instances with the same class together\n",
    "    dataset = sorted(dataset, key=lambda x: x[-1])\n",
    "    return dataset\n",
    "\n",
    "data_file = 'anneal.csv'\n",
    "new_file = \"_unit_test.csv\"\n",
    "missing_value_files = ['breast-cancer.csv', 'hepatitis.csv', 'hypothyroid.csv', 'mushroom.csv', 'primary-tumor.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'cold': 2, 'flu': 3},\n",
       " [{'mild': 2, 'no': 1, 'severe': 2},\n",
       "  {'mild': 2, 'no': 1, 'severe': 2},\n",
       "  {'high': 1, 'normal': 4},\n",
       "  {'no': 1, 'yes': 4}],\n",
       " [[{'mild': 1, 'no': 1},\n",
       "   {'no': 1, 'severe': 1},\n",
       "   {'normal': 2},\n",
       "   {'no': 1, 'yes': 1}],\n",
       "  [{'mild': 1, 'severe': 2},\n",
       "   {'mild': 2, 'severe': 1},\n",
       "   {'high': 1, 'normal': 2},\n",
       "   {'yes': 3}]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train takes a list of instances and returns a 3-tuple containing:\n",
    "# A dictionary of the class distribution of all classes in the dataset\n",
    "# A list of dictionaries, tallying each attribute value for every attribute\n",
    "# A list (for each class) of dictionaries tallying attribute values for\n",
    "# every attribute of a particular class\n",
    "def train(instance_list, missing_value):\n",
    "    data_info = ({}, [], [])\n",
    "\n",
    "    current_class = instance_list[0][-1]\n",
    "    data_info[0][current_class] = 0\n",
    "    data_info[2].append([])\n",
    "    class_index = 0\n",
    "    \n",
    "    # Add attribute lists to store the unique attribute values in\n",
    "    for i in range(len(instance_list[0]) - 1):\n",
    "        data_info[1].append({})\n",
    "        data_info[2][class_index].append({})\n",
    "    \n",
    "    # Tally each value in each attribute for each class\n",
    "    for data in instance_list:\n",
    "#         print(data)\n",
    "        attribute_num = 0\n",
    "\n",
    "        # New class has been detected\n",
    "        if data[-1] != current_class:\n",
    "\n",
    "            # Add data structure to support new class\n",
    "            current_class = data[-1]\n",
    "            data_info[0][current_class] = 0\n",
    "            data_info[2].append([])\n",
    "            class_index += 1\n",
    "            \n",
    "            # Add dictionary for each attribute\n",
    "            for i in range(len(data) - 1):\n",
    "                data_info[2][class_index].append({})\n",
    "        \n",
    "        # Input each instance's attribute into the appropriate dictionary\n",
    "        for attribute in data[:-1]:\n",
    "            \n",
    "            if attribute in data_info[1][attribute_num]:\n",
    "                data_info[1][attribute_num][attribute] += 1\n",
    "            else:\n",
    "                data_info[1][attribute_num][attribute] = 1\n",
    "                \n",
    "            if attribute in data_info[2][class_index][attribute_num]:\n",
    "                data_info[2][class_index][attribute_num][attribute] += 1\n",
    "            else:\n",
    "                data_info[2][class_index][attribute_num][attribute] = 1\n",
    "            attribute_num += 1\n",
    "        \n",
    "        data_info[0][current_class] += 1\n",
    "        \n",
    "    return data_info # Return the 3-tuple\n",
    "\n",
    "\n",
    "# train(preprocess(missing_value_files[0]), \"?\")\n",
    "train(preprocess(new_file), \"?\")\n",
    "\n",
    "# train(preprocess(missing_value_files[-1]), \"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cold\n",
      "flu\n",
      "cold\n",
      "flu\n",
      "cold\n",
      "flu\n",
      "cold\n",
      "flu\n",
      "cold\n",
      "flu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function should predict the class for an instance or a set of instances, based on a trained model \n",
    "def predict(model, instances):\n",
    "    predicted_classes = []\n",
    "    \n",
    "    \n",
    "    # Find class prediction for each class\n",
    "    for data in instances:\n",
    "        class_index = 0\n",
    "        attribute_index = 0\n",
    "        probability_of_class = 0\n",
    "        \n",
    "        # Calculate probability of the instance belonging to a particular class\n",
    "        for class_name in model[0].keys():\n",
    "            \n",
    "            print(class_name)\n",
    "        \n",
    "#         attribute_number = 0\n",
    "#         probability_of_class = []\n",
    "        \n",
    "#         # Find probability of an instance being of a particular class\n",
    "#         for class_index in range(len(model[2])):\n",
    "#             probability = 1.0\n",
    "#             for attribute in model[2][class_index]:\n",
    "#                 if data[attribute_number] in attribute:\n",
    "#                     probability *= attribute[data[attribute_number]] / model[1][class_index]\n",
    "#                 else:\n",
    "#                     probability /= len(model[2][class_index])\n",
    "#             probability_of_class.append(probability)\n",
    "        \n",
    "#         class_index = 0\n",
    "#         highest_probability = 0\n",
    "#         # Find the class with the highest probability\n",
    "#         for i in range(len(probability_of_class)):\n",
    "#             if probability_of_class[i] > highest_probability:\n",
    "#                 highest_probability = probability_of_class[i]\n",
    "#                 class_index = i\n",
    "\n",
    "# #                 print(\"Higher\")\n",
    "# #             elif probability_of_class[i] < highest_probability:\n",
    "# #                 print(\"Less Than\")\n",
    "# #             else:\n",
    "# #                 print(\"Equal Too\")\n",
    "#         print(data, \"has predicted value\", model[0][class_index])\n",
    "#         predicted_classes.append(model[0][class_index])\n",
    "#         print(\"--------------------\")\n",
    "\n",
    "#     #### NAIVE WAY OF PUTTING HIGHEST CLASS AS ALL PREDICTIONS\n",
    "#     top_class = \"\"\n",
    "#     highest = 0\n",
    "#     for i in model[0]:\n",
    "#         if model[0][i] > highest:\n",
    "#             top_class = i\n",
    "#             highest = model[0][i]\n",
    "    \n",
    "#     for j in range(len(instances)):\n",
    "#         predicted_classes.append(top_class)\n",
    "        \n",
    "    return predicted_classes # Return a list of predicted classes\n",
    "\n",
    "predict((train(preprocess(new_file), \"?\")), preprocess(new_file))\n",
    "\n",
    "# predict(train(preprocess(missing_value_files[1]), \"?\"), preprocess(missing_value_files[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluates the performance of the predictor model\n",
    "def evaluate(predictions, dataset):\n",
    "    tries = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == dataset[i][-1]:\n",
    "            correct += 1\n",
    "        tries += 1\n",
    "        \n",
    "    print(\"Correct:\", correct, \"out of\", tries)\n",
    "    print(\"Accuracy Rate (%): \", correct / tries * 100)\n",
    "    print(\"-----------------------------------\")\n",
    "    return\n",
    "\n",
    "# print(\"Preprocess\")\n",
    "# print(preprocess(new_file))\n",
    "# print(\"---------------\")\n",
    "# print(\"Train\")\n",
    "# print((train(preprocess(new_file), \"?\")))\n",
    "# print(\"---------------\")\n",
    "# print(predict((train(preprocess(new_file), \"?\")), preprocess(new_file)))\n",
    "# print(\"---------------\")\n",
    "\n",
    "\n",
    "# for i in missing_value_files:\n",
    "#     evaluate(predict(train(preprocess(i), \"?\"), preprocess(i)), preprocess(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1 --- 1\n",
      "Entropy --- 0.0 ---\n",
      "Final Entropy: 0.0\n",
      "--- 5 --- 6\n",
      "Entropy --- 0.21919533819482817 ---\n",
      "--- 1 --- 6\n",
      "Entropy --- 0.6500224216483541 ---\n",
      "Final Entropy: 0.6500224216483541\n",
      "--- 63 --- 90\n",
      "Entropy --- 0.3602012209808308 ---\n",
      "--- 27 --- 90\n",
      "Entropy --- 0.8812908992306927 ---\n",
      "Final Entropy: 0.8812908992306927\n",
      "--- 40 --- 57\n",
      "Entropy --- 0.35856976791395045 ---\n",
      "--- 17 --- 57\n",
      "Entropy --- 0.8791357668533336 ---\n",
      "Final Entropy: 0.8791357668533336\n",
      "--- 21 --- 36\n",
      "Entropy --- 0.45360442088707204 ---\n",
      "--- 15 --- 36\n",
      "Entropy --- 0.9798687566511528 ---\n",
      "Final Entropy: 0.9798687566511528\n",
      "--- 71 --- 96\n",
      "Entropy --- 0.3218780423580173 ---\n",
      "--- 25 --- 96\n",
      "Entropy --- 0.8273744775003172 ---\n",
      "Final Entropy: 0.8273744775003172\n",
      "ATTR 1.171915868759835\n",
      "--- 5 --- 7\n",
      "Entropy --- 0.3467334479787441 ---\n",
      "--- 2 --- 7\n",
      "Entropy --- 0.863120568566631 ---\n",
      "Final Entropy: 0.863120568566631\n",
      "--- 102 --- 150\n",
      "Entropy --- 0.37834747699658194 ---\n",
      "--- 48 --- 150\n",
      "Entropy --- 0.9043814577244937 ---\n",
      "Final Entropy: 0.9043814577244937\n",
      "--- 94 --- 129\n",
      "Entropy --- 0.33274426319448047 ---\n",
      "--- 35 --- 129\n",
      "Entropy --- 0.843349289138202 ---\n",
      "Final Entropy: 0.843349289138202\n",
      "ATTR 0.26157159931036955\n",
      "--- 2 --- 3\n",
      "Entropy --- 0.38997500048077083 ---\n",
      "--- 1 --- 3\n",
      "Entropy --- 0.9182958340544896 ---\n",
      "Final Entropy: 0.9182958340544896\n",
      "--- 16 --- 22\n",
      "Entropy --- 0.3341320862816707 ---\n",
      "--- 6 --- 22\n",
      "Entropy --- 0.8453509366224364 ---\n",
      "Final Entropy: 0.8453509366224364\n",
      "--- 34 --- 50\n",
      "Entropy --- 0.37834747699658194 ---\n",
      "--- 16 --- 50\n",
      "Entropy --- 0.9043814577244937 ---\n",
      "Final Entropy: 0.9043814577244937\n",
      "--- 4 --- 4\n",
      "Entropy --- 0.0 ---\n",
      "Final Entropy: 0.0\n",
      "--- 5 --- 8\n",
      "Entropy --- 0.4237949406953986 ---\n",
      "--- 3 --- 8\n",
      "Entropy --- 0.954434002924965 ---\n",
      "Final Entropy: 0.954434002924965\n",
      "--- 36 --- 54\n",
      "Entropy --- 0.38997500048077083 ---\n",
      "--- 18 --- 54\n",
      "Entropy --- 0.9182958340544896 ---\n",
      "Final Entropy: 0.9182958340544896\n",
      "--- 7 --- 8\n",
      "Entropy --- 0.1685644431995964 ---\n",
      "--- 1 --- 8\n",
      "Entropy --- 0.5435644431995964 ---\n",
      "Final Entropy: 0.5435644431995964\n",
      "--- 23 --- 30\n",
      "Entropy --- 0.2938852903228209 ---\n",
      "--- 7 --- 30\n",
      "Entropy --- 0.783776947484701 ---\n",
      "Final Entropy: 0.783776947484701\n",
      "--- 35 --- 60\n",
      "Entropy --- 0.45360442088707204 ---\n",
      "--- 25 --- 60\n",
      "Entropy --- 0.9798687566511528 ---\n",
      "Final Entropy: 0.9798687566511528\n",
      "--- 27 --- 28\n",
      "Entropy --- 0.050593583469344984 ---\n",
      "--- 1 --- 28\n",
      "Entropy --- 0.222284830685688 ---\n",
      "Final Entropy: 0.222284830685688\n",
      "--- 12 --- 19\n",
      "Entropy --- 0.4187147448773238 ---\n",
      "--- 7 --- 19\n",
      "Entropy --- 0.9494520153879484 ---\n",
      "Final Entropy: 0.9494520153879484\n",
      "ATTR 2.203687865195325\n",
      "--- 4 --- 10\n",
      "Entropy --- 0.5287712379549449 ---\n",
      "--- 6 --- 10\n",
      "Entropy --- 0.9709505944546686 ---\n",
      "Final Entropy: 0.9709505944546686\n",
      "--- 1 --- 1\n",
      "Entropy --- 0.0 ---\n",
      "Final Entropy: 0.0\n",
      "--- 1 --- 3\n",
      "Entropy --- 0.5283208335737187 ---\n",
      "--- 2 --- 3\n",
      "Entropy --- 0.9182958340544896 ---\n",
      "Final Entropy: 0.9182958340544896\n",
      "--- 3 --- 6\n",
      "Entropy --- 0.5 ---\n",
      "--- 3 --- 6\n",
      "Entropy --- 1.0 ---\n",
      "Final Entropy: 1.0\n",
      "--- 167 --- 213\n",
      "Entropy --- 0.27520136025609515 ---\n",
      "--- 46 --- 213\n",
      "Entropy --- 0.7527262079169682 ---\n",
      "Final Entropy: 0.7527262079169682\n",
      "--- 19 --- 36\n",
      "Entropy --- 0.4866097853326614 ---\n",
      "--- 17 --- 36\n",
      "Entropy --- 0.997772472089982 ---\n",
      "Final Entropy: 0.997772472089982\n",
      "--- 7 --- 17\n",
      "Entropy --- 0.5271032608440674 ---\n",
      "--- 10 --- 17\n",
      "Entropy --- 0.9774178175281716 ---\n",
      "Final Entropy: 0.9774178175281716\n",
      "ATTR 0.5098285097053502\n",
      "--- 171 --- 222\n",
      "Entropy --- 0.29005555450621434 ---\n",
      "--- 51 --- 222\n",
      "Entropy --- 0.7775398641607599 ---\n",
      "Final Entropy: 0.7775398641607599\n",
      "--- 25 --- 56\n",
      "Entropy --- 0.5194190769119997 ---\n",
      "--- 31 --- 56\n",
      "Entropy --- 0.9917033083725818 ---\n",
      "Final Entropy: 0.9917033083725818\n",
      "ATTR -0.09588422611643022\n",
      "--- 59 --- 71\n",
      "Entropy --- 0.22195972025954377 ---\n",
      "--- 12 --- 71\n",
      "Entropy --- 0.6554444445609847 ---\n",
      "Final Entropy: 0.6554444445609847\n",
      "--- 102 --- 130\n",
      "Entropy --- 0.27457024652161394 ---\n",
      "--- 28 --- 130\n",
      "Entropy --- 0.7516499461153355 ---\n",
      "Final Entropy: 0.7516499461153355\n",
      "--- 40 --- 85\n",
      "Entropy --- 0.5117472194119244 ---\n",
      "--- 45 --- 85\n",
      "Entropy --- 0.9975025463691152 ---\n",
      "Final Entropy: 0.9975025463691152\n",
      "ATTR 0.7354767362523946\n",
      "--- 98 --- 134\n",
      "Entropy --- 0.33011325329530816 ---\n",
      "--- 36 --- 134\n",
      "Entropy --- 0.8395304981054318 ---\n",
      "Final Entropy: 0.8395304981054318\n",
      "--- 103 --- 152\n",
      "Entropy --- 0.3804406551632751 ---\n",
      "--- 49 --- 152\n",
      "Entropy --- 0.906938456459923 ---\n",
      "Final Entropy: 0.906938456459923\n",
      "ATTR 0.12178509309726127\n",
      "--- 75 --- 110\n",
      "Entropy --- 0.37673251570144006 ---\n",
      "--- 35 --- 110\n",
      "Entropy --- 0.9023932827949788 ---\n",
      "Final Entropy: 0.9023932827949788\n",
      "--- 20 --- 33\n",
      "Entropy --- 0.4378581966491461 ---\n",
      "--- 13 --- 33\n",
      "Entropy --- 0.9672947789468944 ---\n",
      "Final Entropy: 0.9672947789468944\n",
      "--- 71 --- 97\n",
      "Entropy --- 0.32950274546859426 ---\n",
      "--- 26 --- 97\n",
      "Entropy --- 0.8386398715015523 ---\n",
      "Final Entropy: 0.8386398715015523\n",
      "--- 17 --- 21\n",
      "Entropy --- 0.24678704218967404 ---\n",
      "--- 4 --- 21\n",
      "Entropy --- 0.7024665512903903 ---\n",
      "Final Entropy: 0.7024665512903903\n",
      "--- 18 --- 24\n",
      "Entropy --- 0.31127812445913283 ---\n",
      "--- 6 --- 24\n",
      "Entropy --- 0.8112781244591328 ---\n",
      "Final Entropy: 0.8112781244591328\n",
      "ATTR 1.1315254250983573\n",
      "--- 164 --- 218\n",
      "Entropy --- 0.30891605736720273 ---\n",
      "--- 54 --- 218\n",
      "Entropy --- 0.8076226097576923 ---\n",
      "Final Entropy: 0.8076226097576923\n",
      "--- 37 --- 68\n",
      "Entropy --- 0.47774044997046206 ---\n",
      "--- 31 --- 68\n",
      "Entropy --- 0.9943766625699825 ---\n",
      "Final Entropy: 0.9943766625699825\n",
      "ATTR -0.06072655828569706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function should calculate the Information Gain of an attribute or a set of attribute, with respect to the class\n",
    "def info_gain(model):\n",
    "    attribute_info_gain = []\n",
    "    # Calculate the Information Gain of each attribute\n",
    "    for attribute_num in range(len(model[2][0])):\n",
    "        attribute_totals = []\n",
    "        total_value = {}\n",
    "        \n",
    "        # Find all the unique values for a given attribute\n",
    "        for class_index in range(len(model[0])):\n",
    "            data = model[2][class_index][attribute_num]\n",
    "            \n",
    "            # Adds the class' attribute dictionary to the cumulative dictionary\n",
    "            total_value = {x: total_value.get(x, 0) + data.get(x, 0) for x in set(total_value).union(data)}\n",
    "\n",
    "        # Delete the 'missing values' totals\n",
    "        if \"?\" in total_value:\n",
    "            del total_value[\"?\"]\n",
    "        unique_values = set(total_value.keys())\n",
    "            \n",
    "        mean_info = 0\n",
    "#         print(\"---------------\")\n",
    "#         print(total_value)\n",
    "#         print(sum(total_value.values()))\n",
    "#         print(\"---------------\")\n",
    "        \n",
    "        attribute_entropy = 0\n",
    "        for i in total_value:\n",
    "            attribute_probability = total_value[i] * 1.0 / sum(total_value.values())\n",
    "            attribute_entropy -= attribute_probability * math.log2(attribute_probability)\n",
    "        \n",
    "        # Calculate entropy for all different values within an attribute\n",
    "        for value in unique_values:\n",
    "            entropy = 0\n",
    "            for class_index in range(len(model[0])):\n",
    "                data = model[2][class_index][attribute_num]\n",
    "#                 print(data)\n",
    "                if value in data:\n",
    "                    print(\"---\", data[value], \"---\", total_value[value])\n",
    "                    data_probability = data[value] / total_value[value]\n",
    "                    entropy -= (data_probability * math.log2(data_probability))\n",
    "                    print(\"Entropy ---\", entropy, \"---\")\n",
    "            print(\"Final Entropy:\", entropy)\n",
    "            mean_info += total_value[value] * 1.0 / sum(total_value.values()) * entropy\n",
    "            \n",
    "#         print(\"Mean Info\", mean_info)\n",
    "#         print(\"Attribute Entropy\", attribute_entropy)\n",
    "# #         print(\"---------------\")\n",
    "        print(\"ATTR\", attribute_entropy - mean_info)\n",
    "        # At this point: Found the Mean Info for an attribute\n",
    "        \n",
    "        # Find entropy of the attribute itself\n",
    "        \n",
    "\n",
    "    return attribute_info_gain\n",
    "info_gain(train(preprocess(missing_value_files[0]), \"?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9798687566511528\n"
     ]
    }
   ],
   "source": [
    "print(-21.0/36 * math.log2(21.0/36) - 15.0/36 * math.log2(15.0/36))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': {}}\n"
     ]
    }
   ],
   "source": [
    "a = {}\n",
    "a[\"word\"] = {}\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
